# Paper collection with breif summary
This a paper collection with brief summary for each.
## Photonic in AI

### Photonic computing
| NO. | KEY WORDS | TITLE | KEY INSIGHTS            |
|-----|-----------|-------|-------------------------|
|1    | Photonic computing, MZI| [Deep learning with coherent nanophotonic circuits](https://www.nature.com/articles/nphoton.2017.93) | First to propose MZI do MatMul |
|2    | Photonic neural network, on-chip photonics, Fourier optics | [ReFOCUS: Reusing Light for Efficient Fourier Optics-Based Photonic Neural Network Accelerator](https://doi.org/10.1145/3613424.3623798) |    |

### Photonic in neuramorphic
| NO. | KEY WORDS | TITLE | KEY INSIGHTS |
|-----|-----------|-------|--------------|
|1    | 

## Digital AI

### Matrix Multiplication Acceleration 
| NO. | KEY WORDS | TITLE | KEY INSIGHTS |
|-----|-----------|-------|--------------|
|1    | 


| NO. | KEY WORDS | TITLE | KEY INSIGHTS | 
|-----|-----------|-------|--------------|
|1    | Outer-Product, MatMul Accelerator | [OuterSPACE: An Outer Product based Sparse Matrix Multiplication Accelerator](https://tnm.engin.umich.edu/wp-content/uploads/sites/353/2018/10/2018.02.outerspace.pdf) | |
|6    | reconfigurable dataflow, MatMul Accelerator | [Flexagon: A Multi-Dataflow Sparse-Sparse Matrix Multiplication Accelerator for Efficient DNN Processing](https://arxiv.org/abs/2301.10852) | |


| NO. | KEY WORDS | TITLE | KEY INSIGHTS |
|-----|-----------|-------|--------------|
|1    | 

### Transformer Acceleration
| NO. | KEY WORDS | TITLE | KEY INSIGHTS |
|-----|-----------|-------|--------------|
|1    | QKV generation sparsity, low-precision prediction | [FACT: FFN-Attention Co-optimized Transformer Architecture with Eager Correlation Prediction](https://dl.acm.org/doi/10.1145/3579371.3589057) | QKV generation is time/energy consuming | 


### DNN Acceleration

### Dataflow 
| NO. | KEY WORDS | TITLE | KEY INSIGHTS |
|-----|-----------|-------|--------------|
|1    |reuse type, dataflow  | [Eyeriss: A Spatial Architecture for Energy-Efficient Dataflow for Convolutional Neural Networks](https://ieeexplore.ieee.org/document/7551407) | The first proposal of dataflow taxonomy |
|2    |reuse type, dataflow| [Eyeriss: An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks](https://ieeexplore.ieee.org/document/7738524)| The first proposal of dataflow taxonomy|
|3    |          |[Deep Convolutional Neural Network Architecture With Reconfigurable Computation Patterns](https://ieeexplore.ieee.org/document/7898402) |  |
|4    |          |


### Methodology
| NO. | KEY WORDS | TITLE | KEY INSIGHTS |
|-----|-----------|-------|--------------|
|1    | DNN simulator, systolic array, dataflow | [SCALE-Sim: Systolic CNN Accelerator Simulator](https://arxiv.org/abs/1811.02883) | Answer several questions about impact of hyper-parameters in systolic array (dataflow, array size, array shape) |
|2    | Energy Estimation |[Accelergy: An Architecture-Level Energy Estimation Methodology for Accelerator Designs](https://ieeexplore.ieee.org/document/8942149) | |
|3    | Accelerator, taxonomy |[Sparseloop: An Analytical Approach To Sparse Tensor Accelerator Modeling](http://sparseloop.mit.edu/documents/2022-micro-sparseloop.pdf) | clear taxonomy in compression pattern and jump/gate....|


## Algorithm
### Low Precision Net
| NO. | KEY WORDS | TITLE | KEY INSIGHTS |
|-----|-----------|-------|--------------|
|1    | 



