# [0xx][]
## Overview
* Authors:
* Affiliations: 
* Publication Venue: 
* Link: []()
## Summary: 
### Problem:
### Key idea: 
### Takeaways: 
### Strengths: 
### weaknesses: 
### How can you do better:
### Comments:
1. The first work to apply approximation to the attention weights for computation reduction. However, A3
involves a sorting-based preprocessing phase that needs to be done outside the accelerator, causing Inevitable performance and energy overhead.   --DOTA
2. 